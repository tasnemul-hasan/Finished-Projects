{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9211562,"sourceType":"datasetVersion","datasetId":5569991},{"sourceId":9316711,"sourceType":"datasetVersion","datasetId":5643070}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Github Clone","metadata":{}},{"cell_type":"code","source":"#!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n!pip install -e detectron2_repo\n!pip install ultralytics","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert YOLO to COCO format","metadata":{}},{"cell_type":"code","source":"def convert_yolo_to_coco(images_dir, labels_dir, output_json, class_names):\n    images = []\n    annotations = []\n    ann_id = 0\n\n    # Iterate over the label files in the labels directory\n    for img_id, label_file in enumerate(os.listdir(labels_dir)):\n        if label_file.endswith(\".txt\"):\n            image_id = label_file.replace(\".txt\", \"\")\n            img_path = os.path.join(images_dir, image_id + \".jpg\")\n\n            if not os.path.exists(img_path):\n                print(f\"Image {img_path} not found, skipping.\")\n                continue\n            try:\n                image = Image.open(img_path)\n            except:\n                continue\n                \n            width, height = image.size\n\n            images.append({\n                \"file_name\": image_id + \".jpg\",\n                \"height\": height,\n                \"width\": width,\n                \"id\": img_id\n            })\n\n            with open(os.path.join(labels_dir, label_file)) as f:\n                for line in f:\n                    class_id, x_center, y_center, bbox_width, bbox_height = map(float, line.split())\n\n                    x_min = (x_center - bbox_width / 2) * width\n                    y_min = (y_center - bbox_height / 2) * height\n                    w = bbox_width * width\n                    h = bbox_height * height\n\n                    annotations.append({\n                        \"id\": ann_id,\n                        \"image_id\": img_id,\n                        \"category_id\": int(class_id),\n                        \"bbox\": [x_min, y_min, w, h],\n                        \"area\": w * h,\n                        \"iscrowd\": 0\n                    })\n                    ann_id += 1\n\n    categories = [{\"id\": i, \"name\": name} for i, name in enumerate(class_names)]\n\n    coco_format = {\n        \"images\": images,\n        \"annotations\": annotations,\n        \"categories\": categories\n    }\n\n    with open(output_json, 'w') as outfile:\n        json.dump(coco_format, outfile, indent=4)\n\n# Example usage\nimages_dir = \"/kaggle/input/dataset4/train/images\"\nlabels_dir = \"/kaggle/input/dataset4/train/labels\"\noutput_json = \"/kaggle/working/coco_train_annotations.json\"\nclass_names = [\"suv\", \"car\", \"truck\"]  # Replace with your actual class names\n\n#convert_yolo_to_coco(images_dir, labels_dir, output_json, class_names)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:21:00.800692Z","iopub.execute_input":"2024-09-05T05:21:00.801281Z","iopub.status.idle":"2024-09-05T05:21:00.819383Z","shell.execute_reply.started":"2024-09-05T05:21:00.801234Z","shell.execute_reply":"2024-09-05T05:21:00.818399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detectron 2","metadata":{}},{"cell_type":"markdown","source":"## Libraries","metadata":{}},{"cell_type":"code","source":"# Run after restart session\nimport os\nimport cv2\nimport time\nimport json\nimport torch\nimport shutil\nimport warnings\nimport detectron2\nimport numpy as np\nimport tracemalloc\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom detectron2 import model_zoo\nfrom detectron2.config import get_cfg\nfrom detectron2.structures import Boxes\nfrom IPython.display import clear_output\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.data import build_detection_test_loader\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.engine import DefaultTrainer, DefaultPredictor\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nwarnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*torch.load.*weights_only=False.*\")\nsetup_logger()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:21:00.820512Z","iopub.execute_input":"2024-09-05T05:21:00.820816Z","iopub.status.idle":"2024-09-05T05:21:04.219480Z","shell.execute_reply.started":"2024-09-05T05:21:00.820783Z","shell.execute_reply":"2024-09-05T05:21:04.218380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Path","metadata":{}},{"cell_type":"code","source":"# Register the dataset\ntrain_img_path = '/kaggle/input/dataset4/train/images'\ntrain_json_path = '/kaggle/working/coco_train_annotations.json'\nregister_coco_instances(\"my_train_dataset\", {}, train_json_path, train_img_path)\n\nval_img_path = '/kaggle/input/dataset4/val/images'\nval_json_path = '/kaggle/working/coco_val_annotations.json'\nregister_coco_instances(\"my_val_dataset\", {}, val_json_path, val_img_path)\n\ntest_img_path = '/kaggle/input/dataset4/test/images'\ntest_json_path = '/kaggle/working/coco_test_annotations.json'\nregister_coco_instances(\"my_test_dataset\", {}, test_json_path, test_img_path)\n\ntrain_data = \"my_train_dataset\"\nval_data = \"my_val_dataset\"\ntest_data = \"my_test_dataset\"","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:21:04.220842Z","iopub.execute_input":"2024-09-05T05:21:04.221322Z","iopub.status.idle":"2024-09-05T05:21:04.230303Z","shell.execute_reply.started":"2024-09-05T05:21:04.221288Z","shell.execute_reply":"2024-09-05T05:21:04.229246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup Config","metadata":{}},{"cell_type":"code","source":"def setup_config(model, output_dir, train_data=train_data, val_data=val_data):\n    cfg = get_cfg()\n\n    cfg.merge_from_file(model_zoo.get_config_file(model))\n    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model)\n    cfg.DATASETS.TRAIN = (train_data,)\n    cfg.DATASETS.TEST = (val_data,)\n    cfg.TEST.EVAL_PERIOD = 500\n    cfg.DATALOADER.NUM_WORKERS = 2\n    cfg.SOLVER.IMS_PER_BATCH = 16\n    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # Number of classes for Faster RCNN\n    cfg.MODEL.RETINANET.NUM_CLASSES = 3  # Number of classes for Retina Net\n    cfg.MODEL.MASK_ON = False\n    cfg.MODEL.LOAD_PROPOSALS = False\n\n    # Debug/verbose\n    setup_logger()\n    #logger = logging.getLogger(\"detectron2\")\n    #logger.setLevel(logging.DEBUG)\n    #logger.info(\"Training has started.\")\n    #logger.debug(\"This is a detailed debug message.\")\n\n    # Create the output directory\n    cfg.OUTPUT_DIR = \"/kaggle/working/\" + output_dir\n    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n    return cfg","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:21:04.233416Z","iopub.execute_input":"2024-09-05T05:21:04.233788Z","iopub.status.idle":"2024-09-05T05:21:04.244205Z","shell.execute_reply.started":"2024-09-05T05:21:04.233748Z","shell.execute_reply":"2024-09-05T05:21:04.243028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Detectron 2","metadata":{}},{"cell_type":"code","source":"def train_models(models, output_dirs):\n    for i in range(len(models)):\n        model = models[i]\n        output_dir = output_dirs[i] \n\n        cfg = setup_config(model, output_dir)\n\n        # Adaptive LRs\n        lrs = [0.0001,0.00001]\n        epochs = [500, 1500]\n\n        # Model Training\n        resume_training = False\n        for lr, epoch in zip(lrs, epochs):\n            clear_output()\n\n            cfg.SOLVER.BASE_LR = lr  # Learning rate\n            cfg.SOLVER.MAX_ITER = epoch  # Adjust the number of iterations/epochs\n\n            # Start training\n            trainer = DefaultTrainer(cfg)\n            trainer.resume_or_load(resume=resume_training)\n            trainer.train()\n\n            if (resume_training == False):\n                resume_training = True     # after first loop, training will be resumed from previous state\n\n\n        cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n        evaluator = COCOEvaluator(test_data, cfg, False, output_dir=cfg.OUTPUT_DIR)\n        test_loader = build_detection_test_loader(cfg, test_data)\n        eval_results = inference_on_dataset(trainer.model, test_loader, evaluator)\n\n        with open(output_dirs[i] + \"_results.txt\", \"w\") as f:\n            f.write(\"Evaluation Metrics:\\n\")\n            for metric, value in eval_results.items():\n                f.write(f\"{metric}: {value}\\n\")\n                \n                \n# Detection Models\ndetectron_models = [\n    \"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\", \n    \"COCO-Detection/retinanet_R_50_FPN_1x.yaml\",\n    \"Misc/cascade_mask_rcnn_R_50_FPN_1x.yaml\"\n]\ndetectron_output_dirs = [\"output_faster_rcnn\", \"output_retinanet\", \"output_cascade_rcnn\"]\n                \n#train_models(detectron_models, detectron_output_dirs)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:21:04.245750Z","iopub.execute_input":"2024-09-05T05:21:04.246406Z","iopub.status.idle":"2024-09-05T05:21:04.259425Z","shell.execute_reply.started":"2024-09-05T05:21:04.246359Z","shell.execute_reply":"2024-09-05T05:21:04.258402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Yolov5","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics\nfrom ultralytics import YOLO\nimport os\nos.environ['WANDB_DISABLED'] = 'true'\n\n# Train\n#model = YOLO('/kaggle/working/output_yolo/train/weights/best.pt')  # Load a pre-trained YOLOv5 model\n#model.train(data='/kaggle/input/dataset4/train_data.yaml', epochs=80, batch=16, imgsz=640, plots=True,project='output_yolo', lr0=0.0001, cos_lr=True, lrf=0.01)  # Train the model\n\n# Validation\n#model = YOLO('/kaggle/working/output_yolo/train2/weights/best.pt')  # Load a pre-trained YOLOv5 model\n#model.val(data='/kaggle/input/dataset4/train_data.yaml', plots=True, project='output_yolo_test')  # Validate the model\n\n# Test\n#model = YOLO('/kaggle/working/output_yolo/train/weights/best.pt')  # Load a pre-trained YOLOv5 model\n#model.val(data='/kaggle/input/dataset4/test_data.yaml', plots=True, project='output_yolo_test')  # Test the model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performance Analysis","metadata":{}},{"cell_type":"markdown","source":"### Tool Functions","metadata":{}},{"cell_type":"code","source":"def draw_bounding_boxes(image, boxes, classes, gt, plot=False):\n    # Draw ground truth bounding boxes\n    if gt:\n        color = (0, 0, 255)\n    else:\n        color = (0, 255, 0)\n\n    item_no=1\n    for box,clas in zip(boxes, classes):\n        x_min, y_min, x_max, y_max = map(int, box)\n        label = f'{item_no}__{clas}'\n        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 1)  # Blue for ground truth\n        cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n\n        item_no +=1\n        \n    if(plot==True):\n        plt.figure(figsize=(12, 8))\n        plt.imshow(image)\n        plt.title(\"Predicted Bounding Boxes and Classes\")\n        plt.axis('off')  # Hide axis\n        plt.show()\n\n    return image\n\n\ndef xywhn_to_xyxy(cx, cy, w, h, image_width, image_height):\n    \"\"\"\n    Convert YOLO format [cx, cy, w, h] with normalized values to [x_min, y_min, x_max, y_max] in pixel values.\n\n    Parameters:\n    - cx, cy: Center coordinates (normalized)\n    - w, h: Width and height (normalized)\n    - image_width: Width of the image in pixels\n    - image_height: Height of the image in pixels\n\n    Returns:\n    - A list [x_min, y_min, x_max, y_max] in pixel values\n    \"\"\"\n    x_min = (cx - w / 2) * image_width\n    y_min = (cy - h / 2) * image_height\n    x_max = (cx + w / 2) * image_width\n    y_max = (cy + h / 2) * image_height\n    return [x_min, y_min, x_max, y_max]","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:21:04.261045Z","iopub.execute_input":"2024-09-05T05:21:04.261442Z","iopub.status.idle":"2024-09-05T05:21:04.275275Z","shell.execute_reply.started":"2024-09-05T05:21:04.261399Z","shell.execute_reply":"2024-09-05T05:21:04.274013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Models","metadata":{}},{"cell_type":"code","source":"def load_yolo(image, weight, threshold):\n    start_time = time.time()\n    tracemalloc.start()\n    #-----------------------\n    model = YOLO(weight)\n    results = model.predict(image, conf=threshold)\n    pred_boxes = results[0].boxes.xyxy.cpu().numpy()  # Predicted bounding boxes\n    pred_classes = results[0].boxes.data[:, 5].cpu().numpy()  # Predicted class IDs\n    pred_scores = results[0].boxes.data[:, 4].cpu().numpy()  # Confidence scores\n    #------------------------\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    end_time = time.time()\n    execution_time = end_time - start_time\n    execution_time = np.round(execution_time,2)\n    return pred_boxes, pred_classes, pred_scores, execution_time\n\n\n\ndef load_detectron2(image, model, threshold, all_models=detectron_models, all_dirs=detectron_output_dirs):\n    start_time = time.time()\n    tracemalloc.start()\n    #------------------------\n    model_index = all_models.index(model)\n    output_dir = all_dirs[model_index]\n    cfg = setup_config(model, output_dir)\n    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n    \n    # Step 2: Create a Predictor\n    predictor = DefaultPredictor(cfg)\n    outputs = predictor(image)\n    \n    custom_threshold = threshold\n    instances = outputs[\"instances\"]\n\n    # Extract the bounding boxes, class labels, and scores\n    boxes = instances.pred_boxes if instances.has(\"pred_boxes\") else None\n    scores = instances.scores if instances.has(\"scores\") else None\n    classes = instances.pred_classes if instances.has(\"pred_classes\") else None\n\n    # Filter predictions based on the custom threshold\n    filtered_indices = scores > custom_threshold\n    filtered_boxes = boxes[filtered_indices]\n    filtered_scores = scores[filtered_indices]\n    filtered_classes = classes[filtered_indices]\n\n    pred_boxes = filtered_boxes.tensor.to('cpu').tolist()\n    pred_scores = filtered_scores.to('cpu').tolist()\n    pred_classes = filtered_classes.to('cpu').tolist()\n    #-------------------------------------------------\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    end_time = time.time()\n    execution_time = end_time - start_time\n    execution_time = np.round(execution_time,2)\n    \n    return pred_boxes, pred_classes, pred_scores, execution_time","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:21:04.276459Z","iopub.execute_input":"2024-09-05T05:21:04.276790Z","iopub.status.idle":"2024-09-05T05:21:04.290588Z","shell.execute_reply.started":"2024-09-05T05:21:04.276757Z","shell.execute_reply":"2024-09-05T05:21:04.289559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculate IOU","metadata":{}},{"cell_type":"code","source":"def calculate_iou(box1, box2):\n    \"\"\"\n    Calculate Intersection over Union (IoU) between two bounding boxes.\n    box1, box2 format: [x_min, y_min, x_max, y_max]\n    \"\"\"\n    x1 = max(box1[0], box2[0])\n    y1 = max(box1[1], box2[1])\n    x2 = min(box1[2], box2[2])\n    y2 = min(box1[3], box2[3])\n\n    # Calculate the area of the intersection\n    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n\n    # Calculate the areas of each box\n    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n\n    # Calculate the union area\n    union = box1_area + box2_area - intersection\n\n    # Calculate IoU\n    iou = intersection / union if union > 0 else 0\n    return iou","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:21:04.291753Z","iopub.execute_input":"2024-09-05T05:21:04.292117Z","iopub.status.idle":"2024-09-05T05:21:04.301607Z","shell.execute_reply.started":"2024-09-05T05:21:04.292065Z","shell.execute_reply":"2024-09-05T05:21:04.300572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def performance_metrics(test_folder, model_name, model, threshold):\n    data = []\n    execution_times = []\n    target_found_list = []\n    class_identified_list = []\n    multiclass_error_list = []\n    \n    img_list = os.listdir(test_folder+'images/')\n    img_list.sort()\n    for img in img_list:\n        # Load image\n        image_path = test_folder + '/images/'+ img\n        image = cv2.imread(image_path)\n\n        \n        # Extract predictions\n        if model_name=='yolo':\n            pred_boxes, pred_classes, pred_scores, execution_time = load_yolo(image, model, threshold)\n        elif model_name in [\"faster_rcnn\", \"retinanet\", \"cascade_rcnn\"]:\n            pred_boxes, pred_classes, pred_scores, execution_time = load_detectron2(image, model, threshold)\n        else:\n            print('Model Doesnt Exists')\n           \n        # Extract ground truth\n        label_path =test_folder + 'labels/' + img[:-4] + '.txt'\n        with open(label_path, 'r') as f:\n            lines = f.readlines()\n            \n        try:\n            target_gt = lines[0].split()\n        except:\n            continue\n            \n        target_gt = [float(x) for x in target_gt]  # convert string to float\n        target_box = xywhn_to_xyxy(target_gt[1], target_gt[2], target_gt[3], target_gt[4], image_width=image.shape[1], image_height=image.shape[0])\n        target_class = 1  # in the dataset our target is only car. Only target object is annotated in the tracking dataset\n\n        \n        \n        # Compare each predicted box with ground truth boxes\n        bbox_matched_list = []\n        for i, pred_box in enumerate(pred_boxes):\n            iou = calculate_iou(pred_box, target_box)\n            #print(f'Predicted class: {pred_classes[i]}, IoU with ground truth: {iou:.2f}, Confidence: {pred_scores[i]:.2f}')\n            if iou > 0.8:\n                bbox_matched_list.append(pred_classes[i])\n            \n            \n            \n        # Calculate performance metrics\n        target_found = 1 if len(bbox_matched_list) > 0 else 0.0\n        class_identified = 1 if target_class in bbox_matched_list else 0.0\n\n        if target_found and class_identified:\n            multiclass_error = (len(bbox_matched_list) - 1) / (len(pred_boxes) - 1) if len(pred_boxes) > 1 else 0.0\n        else:\n            multiclass_error = 0.0\n            \n        # Log metrics per image\n        log = f'\\n{img[:-4]} \\t Target found: {target_found} \\t Class identified: {class_identified} \\t Multiclass error: {np.round(multiclass_error, 2)}'\n        clear_output()\n        print('\\n Running Model: ', model_name, '\\t', 'Threshold: ', threshold)\n        print(log)\n        \n        data.append(log)\n        target_found_list.append(target_found)\n        class_identified_list.append(class_identified)\n        multiclass_error_list.append(np.round(multiclass_error, 2))\n        execution_times.append(execution_time)\n\n    target_found_acc = np.mean(target_found_list)\n    class_identified_acc = np.mean(class_identified_list)\n    multiclass_error_avg = np.round(np.mean(multiclass_error_list), 2)\n    execution_times_avg =  np.round(np.mean(execution_times), 2)\n    \n    log = f'\\n\\n\\nTarget found accuracy: {target_found_acc} \\t Class identified accuracy: {class_identified_acc} \\t Multiclass error: {multiclass_error_avg} \\t Average Execution Time: {execution_times_avg}s'\n    print(log)\n    data.append(log)\n\n    # Save results to a text file\n    txt_folder = '/kaggle/working/txt_results/'\n    with open(txt_folder + f'{model_name}_threshold_{threshold}_results.txt', 'w') as f:\n      for log in data:\n        f.write(log)\n  ","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:21:04.302930Z","iopub.execute_input":"2024-09-05T05:21:04.303263Z","iopub.status.idle":"2024-09-05T05:21:04.320209Z","shell.execute_reply.started":"2024-09-05T05:21:04.303230Z","shell.execute_reply":"2024-09-05T05:21:04.319226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load ground truths\ntest_folder = '/kaggle/input/tracking-ground-truth/test/'\nthresholds = [0.5, 0.3, 0.1, 1e-5]\nmodel_names = [\"faster_rcnn\", \"retinanet\", \"cascade_rcnn\", 'yolo']\n\nmodel_wgts = detectron_models.copy()\nmodel_wgts.append('/kaggle/working/output_yolo/train2/weights/best.pt')\n\nfor model_name, model in zip(model_names, model_wgts):\n    for threshold in thresholds:\n        performance_metrics(test_folder, model_name, model, threshold)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T05:21:04.517383Z","iopub.execute_input":"2024-09-05T05:21:04.517694Z","iopub.status.idle":"2024-09-05T10:28:39.258261Z","shell.execute_reply.started":"2024-09-05T05:21:04.517661Z","shell.execute_reply":"2024-09-05T10:28:39.257325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrics on Test Datasets","metadata":{}},{"cell_type":"code","source":"# Make Zip to download all results\nimport shutil\nimport os\nimport pandas as pd\n\ntxt_folder = '/kaggle/working/txt_results/'\ncolumns=['Model_name', 'Avg_target_found_acc', 'Avg_class_identified_acc', 'Avg_multi_class_error', 'Avg_execution_time']\n\ndata_row = []\nthresholds = [0.5, 0.3, 0.1, 1e-5]\nmodel_names = [\"faster_rcnn\", \"retinanet\", \"cascade_rcnn\", 'yolo']\n\nfor model in model_names:\n    for threshold in thresholds:\n        file = f'{model}_threshold_{threshold}_results.txt'\n\n        with open(txt_folder + file, 'r') as f:\n            lines = f.readlines()\n\n        values = []\n        values.append(f'{model}_{threshold}')\n        split_line = re.split(r'[\\t\\s]+|s', lines[-1])\n        split_line = [x for x in split_line if x]\n\n        for data in split_line:\n            try:\n                values.append(float(data))\n            except:\n                pass\n        \n        data_row.append(values)\n\ndf = pd.DataFrame(data_row, columns=columns)   \ndf.to_csv(txt_folder + 'All_detections_output.csv', index=False)\ndf","metadata":{"execution":{"iopub.status.busy":"2024-10-02T17:28:34.650440Z","iopub.execute_input":"2024-10-02T17:28:34.650813Z","iopub.status.idle":"2024-10-02T17:28:34.686126Z","shell.execute_reply.started":"2024-10-02T17:28:34.650779Z","shell.execute_reply":"2024-10-02T17:28:34.685102Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"            Model_name  Avg_target_found_acc  Avg_class_identified_acc  \\\n0      faster_rcnn_0.5              0.848610                  0.787848   \n1      faster_rcnn_0.3              0.886715                  0.883625   \n2      faster_rcnn_0.1              0.911432                  0.899073   \n3    faster_rcnn_1e-05              0.915551                  0.899073   \n4        retinanet_0.5              0.819773                  0.819773   \n5        retinanet_0.3              0.859938                  0.857878   \n6        retinanet_0.1              0.881565                  0.875386   \n7      retinanet_1e-05              0.881565                  0.875386   \n8     cascade_rcnn_0.5              0.768280                  0.768280   \n9     cascade_rcnn_0.3              0.908342                  0.907312   \n10    cascade_rcnn_0.1              0.916581                  0.915551   \n11  cascade_rcnn_1e-05              0.918641                  0.915551   \n12            yolo_0.5              0.430484                  0.430484   \n13            yolo_0.3              0.490216                  0.489186   \n14            yolo_0.1              0.546859                  0.543769   \n15          yolo_1e-05              0.625129                  0.604531   \n\n    Avg_multi_class_error  Avg_execution_time  \n0                    0.12                1.25  \n1                    0.20                1.24  \n2                    0.15                1.23  \n3                    0.12                1.22  \n4                    0.07                1.09  \n5                    0.34                1.09  \n6                    0.13                1.09  \n7                    0.03                1.10  \n8                    0.00                1.83  \n9                    0.25                1.87  \n10                   0.19                1.87  \n11                   0.18                1.87  \n12                   0.00                0.49  \n13                   0.00                0.49  \n14                   0.00                0.49  \n15                   0.00                0.48  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model_name</th>\n      <th>Avg_target_found_acc</th>\n      <th>Avg_class_identified_acc</th>\n      <th>Avg_multi_class_error</th>\n      <th>Avg_execution_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>faster_rcnn_0.5</td>\n      <td>0.848610</td>\n      <td>0.787848</td>\n      <td>0.12</td>\n      <td>1.25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>faster_rcnn_0.3</td>\n      <td>0.886715</td>\n      <td>0.883625</td>\n      <td>0.20</td>\n      <td>1.24</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>faster_rcnn_0.1</td>\n      <td>0.911432</td>\n      <td>0.899073</td>\n      <td>0.15</td>\n      <td>1.23</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>faster_rcnn_1e-05</td>\n      <td>0.915551</td>\n      <td>0.899073</td>\n      <td>0.12</td>\n      <td>1.22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>retinanet_0.5</td>\n      <td>0.819773</td>\n      <td>0.819773</td>\n      <td>0.07</td>\n      <td>1.09</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>retinanet_0.3</td>\n      <td>0.859938</td>\n      <td>0.857878</td>\n      <td>0.34</td>\n      <td>1.09</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>retinanet_0.1</td>\n      <td>0.881565</td>\n      <td>0.875386</td>\n      <td>0.13</td>\n      <td>1.09</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>retinanet_1e-05</td>\n      <td>0.881565</td>\n      <td>0.875386</td>\n      <td>0.03</td>\n      <td>1.10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>cascade_rcnn_0.5</td>\n      <td>0.768280</td>\n      <td>0.768280</td>\n      <td>0.00</td>\n      <td>1.83</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>cascade_rcnn_0.3</td>\n      <td>0.908342</td>\n      <td>0.907312</td>\n      <td>0.25</td>\n      <td>1.87</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>cascade_rcnn_0.1</td>\n      <td>0.916581</td>\n      <td>0.915551</td>\n      <td>0.19</td>\n      <td>1.87</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>cascade_rcnn_1e-05</td>\n      <td>0.918641</td>\n      <td>0.915551</td>\n      <td>0.18</td>\n      <td>1.87</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>yolo_0.5</td>\n      <td>0.430484</td>\n      <td>0.430484</td>\n      <td>0.00</td>\n      <td>0.49</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>yolo_0.3</td>\n      <td>0.490216</td>\n      <td>0.489186</td>\n      <td>0.00</td>\n      <td>0.49</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>yolo_0.1</td>\n      <td>0.546859</td>\n      <td>0.543769</td>\n      <td>0.00</td>\n      <td>0.49</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>yolo_1e-05</td>\n      <td>0.625129</td>\n      <td>0.604531</td>\n      <td>0.00</td>\n      <td>0.48</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Convert CSV for Statical Analysis","metadata":{}},{"cell_type":"code","source":"df_combined_statics = df.copy()\n\nselected_column = ['Avg_target_found_acc', 'Avg_class_identified_acc']\n\nfor column in selected_column:\n    df_combined_statics[column] = df_combined_statics[column] * -1\n\n#df_combined_statics.to_csv\ndf_combined_statics_transposed = df_combined_statics.copy().T\ndf_combined_statics_transposed = df_combined_statics_transposed.reset_index()\ndf_combined_statics_transposed.to_csv(txt_folder + '/All_detections_output_statics.csv', index=False, sep=',')\ndf_combined_statics_transposed","metadata":{"execution":{"iopub.status.busy":"2024-10-02T17:40:00.789794Z","iopub.execute_input":"2024-10-02T17:40:00.790268Z","iopub.status.idle":"2024-10-02T17:40:00.817073Z","shell.execute_reply.started":"2024-10-02T17:40:00.790226Z","shell.execute_reply":"2024-10-02T17:40:00.816095Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                      index                0                1  \\\n0                Model_name  faster_rcnn_0.5  faster_rcnn_0.3   \n1      Avg_target_found_acc         -0.84861        -0.886715   \n2  Avg_class_identified_acc        -0.787848        -0.883625   \n3     Avg_multi_class_error             0.12              0.2   \n4        Avg_execution_time             1.25             1.24   \n\n                 2                  3              4              5  \\\n0  faster_rcnn_0.1  faster_rcnn_1e-05  retinanet_0.5  retinanet_0.3   \n1        -0.911432          -0.915551      -0.819773      -0.859938   \n2        -0.899073          -0.899073      -0.819773      -0.857878   \n3             0.15               0.12           0.07           0.34   \n4             1.23               1.22           1.09           1.09   \n\n               6                7                 8                 9  \\\n0  retinanet_0.1  retinanet_1e-05  cascade_rcnn_0.5  cascade_rcnn_0.3   \n1      -0.881565        -0.881565          -0.76828         -0.908342   \n2      -0.875386        -0.875386          -0.76828         -0.907312   \n3           0.13             0.03               0.0              0.25   \n4           1.09              1.1              1.83              1.87   \n\n                 10                  11        12        13        14  \\\n0  cascade_rcnn_0.1  cascade_rcnn_1e-05  yolo_0.5  yolo_0.3  yolo_0.1   \n1         -0.916581           -0.918641 -0.430484 -0.490216 -0.546859   \n2         -0.915551           -0.915551 -0.430484 -0.489186 -0.543769   \n3              0.19                0.18       0.0       0.0       0.0   \n4              1.87                1.87      0.49      0.49      0.49   \n\n           15  \n0  yolo_1e-05  \n1   -0.625129  \n2   -0.604531  \n3         0.0  \n4        0.48  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Model_name</td>\n      <td>faster_rcnn_0.5</td>\n      <td>faster_rcnn_0.3</td>\n      <td>faster_rcnn_0.1</td>\n      <td>faster_rcnn_1e-05</td>\n      <td>retinanet_0.5</td>\n      <td>retinanet_0.3</td>\n      <td>retinanet_0.1</td>\n      <td>retinanet_1e-05</td>\n      <td>cascade_rcnn_0.5</td>\n      <td>cascade_rcnn_0.3</td>\n      <td>cascade_rcnn_0.1</td>\n      <td>cascade_rcnn_1e-05</td>\n      <td>yolo_0.5</td>\n      <td>yolo_0.3</td>\n      <td>yolo_0.1</td>\n      <td>yolo_1e-05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Avg_target_found_acc</td>\n      <td>-0.84861</td>\n      <td>-0.886715</td>\n      <td>-0.911432</td>\n      <td>-0.915551</td>\n      <td>-0.819773</td>\n      <td>-0.859938</td>\n      <td>-0.881565</td>\n      <td>-0.881565</td>\n      <td>-0.76828</td>\n      <td>-0.908342</td>\n      <td>-0.916581</td>\n      <td>-0.918641</td>\n      <td>-0.430484</td>\n      <td>-0.490216</td>\n      <td>-0.546859</td>\n      <td>-0.625129</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Avg_class_identified_acc</td>\n      <td>-0.787848</td>\n      <td>-0.883625</td>\n      <td>-0.899073</td>\n      <td>-0.899073</td>\n      <td>-0.819773</td>\n      <td>-0.857878</td>\n      <td>-0.875386</td>\n      <td>-0.875386</td>\n      <td>-0.76828</td>\n      <td>-0.907312</td>\n      <td>-0.915551</td>\n      <td>-0.915551</td>\n      <td>-0.430484</td>\n      <td>-0.489186</td>\n      <td>-0.543769</td>\n      <td>-0.604531</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Avg_multi_class_error</td>\n      <td>0.12</td>\n      <td>0.2</td>\n      <td>0.15</td>\n      <td>0.12</td>\n      <td>0.07</td>\n      <td>0.34</td>\n      <td>0.13</td>\n      <td>0.03</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.19</td>\n      <td>0.18</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Avg_execution_time</td>\n      <td>1.25</td>\n      <td>1.24</td>\n      <td>1.23</td>\n      <td>1.22</td>\n      <td>1.09</td>\n      <td>1.09</td>\n      <td>1.09</td>\n      <td>1.1</td>\n      <td>1.83</td>\n      <td>1.87</td>\n      <td>1.87</td>\n      <td>1.87</td>\n      <td>0.49</td>\n      <td>0.49</td>\n      <td>0.49</td>\n      <td>0.48</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Make Zip to download all results\n\nOUTPUT_NAME = f'/kaggle/working/Tracker_Output'\nDIRECTORY_TO_ZIP = f'/kaggle/working/Output'\n\nprint(DIRECTORY_TO_ZIP)\nshutil.make_archive(OUTPUT_NAME, 'zip', DIRECTORY_TO_ZIP)","metadata":{},"execution_count":null,"outputs":[]}]}