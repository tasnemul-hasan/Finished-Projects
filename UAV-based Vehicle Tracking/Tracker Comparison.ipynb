{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6368074,"sourceType":"datasetVersion","datasetId":3540471},{"sourceId":8450907,"sourceType":"datasetVersion","datasetId":5036266}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Building the Boxmot Module","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics\n!git clone https://github.com/KeeganFernandesWork/yolo_tracking\n%cd yolo_tracking\n!pip install -r requirements.txt\n!pip install .\n\nfrom IPython.display import clear_output\nclear_output(wait=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:58:01.324369Z","iopub.execute_input":"2024-05-20T04:58:01.324704Z","iopub.status.idle":"2024-05-20T04:58:40.290962Z","shell.execute_reply.started":"2024-05-20T04:58:01.324678Z","shell.execute_reply":"2024-05-20T04:58:40.289870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nfrom IPython.display import display\nfrom PIL import Image, ImageOps\nimport matplotlib.pyplot as plt\nfrom ultralytics import YOLO\nfrom pathlib import Path\nimport numpy as np\nimport tracemalloc\nimport shutil\nimport time\nimport PIL\nimport cv2\nimport os\nimport sys","metadata":{"_uuid":"8f90280b-8fc1-41d7-b4bf-8c0d88dd5ee0","_cell_guid":"a15ac88f-5cc8-4820-bc93-204560c500ee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-20T04:58:40.296017Z","iopub.execute_input":"2024-05-20T04:58:40.296288Z","iopub.status.idle":"2024-05-20T04:58:42.134550Z","shell.execute_reply.started":"2024-05-20T04:58:40.296259Z","shell.execute_reply":"2024-05-20T04:58:42.133578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from boxmot import (OCSORT, BoTSORT, BYTETracker, DeepOCSORT, StrongSORT,create_tracker, get_tracker_config)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:58:42.136220Z","iopub.execute_input":"2024-05-20T04:58:42.137268Z","iopub.status.idle":"2024-05-20T04:58:42.730527Z","shell.execute_reply.started":"2024-05-20T04:58:42.137231Z","shell.execute_reply":"2024-05-20T04:58:42.729571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Video Writer","metadata":{}},{"cell_type":"code","source":"def create_video_writer(video_cap, output_filename):\n\n    # grab the width, height, and fps of the frames in the video stream.\n    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n\n    # initialize the FourCC and a video writer object\n    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n    writer = cv2.VideoWriter(output_filename, fourcc, fps,\n                             (frame_width, frame_height))\n\n    return writer","metadata":{"_uuid":"5b27fb1c-e426-45ef-a2c6-9261f1d6d110","_cell_guid":"0de24502-e2ea-4a5d-990e-71f580f78513","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-20T04:58:42.732991Z","iopub.execute_input":"2024-05-20T04:58:42.733499Z","iopub.status.idle":"2024-05-20T04:58:42.739459Z","shell.execute_reply.started":"2024-05-20T04:58:42.733471Z","shell.execute_reply":"2024-05-20T04:58:42.738574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color = (0, 0, 255)  # BGR\nthickness = 10\nfontscale = 2\n\ndevice = \"cuda:0\" # cuda:0 , cpu\nfp16 = True # True if gpu available\n# load the pre-trained YOLOv8n model\n\nt = 6    #test video no\nm = 9    #YOLO model no\n\nout_dir = f'/kaggle/working/Test{t}/Y{m}_T{t}_NoTarget'\n\nmodel = YOLO(f\"/kaggle/working/Weights/Yolo{m}_best.pt\")\nsource = f\"/kaggle/input/videos-target/Test{t}.mp4\"\n\ntarget_obj_img = np.array([]) # if we have no target and we want to track all objects\n#target_obj_img = cv2.imread(f'/kaggle/input/videos-target/Test{t}Target.jpg') ","metadata":{"_uuid":"7b034df8-bce5-48d8-9884-9aeb9846eecb","_cell_guid":"e7a9dabf-7a39-4a72-aa4b-7789d036c7f1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-20T05:45:55.686821Z","iopub.execute_input":"2024-05-20T05:45:55.687200Z","iopub.status.idle":"2024-05-20T05:45:55.816316Z","shell.execute_reply.started":"2024-05-20T05:45:55.687159Z","shell.execute_reply":"2024-05-20T05:45:55.815298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SIFT Feature Matching","metadata":{}},{"cell_type":"code","source":"def crop(frame, coords, save, obj_name):\n    frame_np_to_PIL = Image.fromarray(frame)        # change to PIL format for easy croping\n    cropped_obj_PIL = frame_np_to_PIL.crop(coords)  # do crop\n    cropped_obj_to_np = np.asarray(cropped_obj_PIL) # convert to cv2 format\n    cropped_obj_rgb = cv2.cvtColor(cropped_obj_to_np, cv2.COLOR_BGR2RGB)  # PIL was BGR format, need to convert in original RGB\n    #display(PIL.Image.fromarray(cropped_obj_rgb))   # display RGB for troubleshooting\n\n    if save == True:\n        cv2.imwrite(obj_name, cropped_obj_to_np)\n        \n    return cropped_obj_to_np\n\n\ndef SIFTFeatureMatchine(target_obj, all_obj, frameNo):\n    target_obj_bw = cv2.cvtColor(np.array(target_obj), cv2.COLOR_BGR2GRAY)\n    \n    good_match_list = []\n    i=0\n    for current_obj in all_obj:\n        current_obj_bw = cv2.cvtColor(np.array(current_obj), cv2.COLOR_BGR2GRAY)\n        \n        reference_height, reference_width = current_obj_bw.shape\n        # Resize the target image to match the dimensions of the reference image\n        target_obj_bw = cv2.resize(target_obj, (reference_width, reference_height))\n        \n        sift = cv2.SIFT_create()\n        target_obj_keypoints, target_obj_descriptors = sift.detectAndCompute(target_obj_bw, None)\n        current_obj_keypoints, current_obj_descriptors = sift.detectAndCompute(current_obj_bw, None)\n\n        matcher = cv2.BFMatcher()\n        matches = matcher.knnMatch(target_obj_descriptors, current_obj_descriptors, k=2)\n\n        good = []\n        try:  # error handling: ValueError: not enough values to unpack (expected 2, got 1)\n            for m, n in matches:\n                if m.distance < 0.75 * n.distance:\n                    good.append([m])\n\n            good_match_list.append(len(good))\n        except:\n            return -1\n        \n        '''\n        # Keypoint matching visualization\n        if frameNo in [317, 332, 350, 356, 357]:\n            final_img = cv2.drawMatchesKnn(target_obj_bw,target_obj_keypoints,current_obj_bw,current_obj_keypoints,good,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n            display(PIL.Image.fromarray(final_img))\n            print('FrameNo:',frameNo, ' ObjNo: ', i)\n            fileName = out_dir + 'Diagnosis/Frame_No_' + str(frameNo) + 'Object_No_' + str(i)\n            cv2.imwrite(fileName + '.jpg', final_img)\n            i+=1\n        '''\n    \n    max_features_matched = max(good_match_list)\n    if max_features_matched>5:   # if no match found\n        target_obj_index = good_match_list.index(max_features_matched)\n        return target_obj_index\n    else:\n        return -1\n\n\n\ndef findTargetObjectIndex(frame, results, target_obj_img, frameNo, obj_dir=''):\n    xyxys = results.boxes.xyxy\n    \n    if len(obj_dir)>0:\n        save = True\n    else:\n        save = False\n    \n    crop_obj_list = []\n    for i in range(len(results)):\n        bbox = (int(xyxys[i][0]), int(xyxys[i][1]), int(xyxys[i][2]), int(xyxys[i][3]))\n\n        obj_name= f'{obj_dir}/Obj_{i}.jpg'\n        crop_obj = crop(frame, bbox, save, obj_name)\n        \n        crop_obj_list.append(crop_obj)\n\n    if(target_obj_img.size != 0 and len(crop_obj_list)>0):\n        target_obj_index = SIFTFeatureMatchine(target_obj_img, crop_obj_list, frameNo)\n        print('FrameNo:',frameNo, ' Target Index: ', target_obj_index)\n        \n        if target_obj_index == -1:\n            return np.array([[0, 0, 0, 0, 0, 0, 0]])\n        else:\n            return results[target_obj_index]\n        \n    else:\n        return results","metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:58:43.136882Z","iopub.execute_input":"2024-05-20T04:58:43.137339Z","iopub.status.idle":"2024-05-20T04:58:43.157626Z","shell.execute_reply.started":"2024-05-20T04:58:43.137303Z","shell.execute_reply":"2024-05-20T04:58:43.156719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing DeepOCSORT","metadata":{}},{"cell_type":"code","source":"#help(DeepOCSORT)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:58:43.159141Z","iopub.execute_input":"2024-05-20T04:58:43.160323Z","iopub.status.idle":"2024-05-20T04:58:43.171689Z","shell.execute_reply.started":"2024-05-20T04:58:43.160289Z","shell.execute_reply":"2024-05-20T04:58:43.170574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\ntracemalloc.start()","metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:58:43.172952Z","iopub.execute_input":"2024-05-20T04:58:43.173414Z","iopub.status.idle":"2024-05-20T04:58:43.182062Z","shell.execute_reply.started":"2024-05-20T04:58:43.173380Z","shell.execute_reply":"2024-05-20T04:58:43.180584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tracker = DeepOCSORT(\n    model_weights=Path('osnet_x0_25_msmt17.pt'), # which ReID model to use\n    device=device,\n    fp16=fp16\n)\nvid = cv2.VideoCapture(source)\nwriter = create_video_writer(vid, out_dir + \"DeepOCSORT.mp4\")\n\nframeNo=0\nwhile True:       \n    clear_output(wait=False)\n    ret, im = vid.read()\n\n    # if video frames end\n    if not ret:\n        break\n    else:\n        results = model.predict(im)[0]\n\n    if np.array(results.boxes.data.tolist()).ndim < 2:\n        continue\n\n    new_results = findTargetObjectIndex(im, results, target_obj_img, frameNo, obj_dir='')\n    try:\n        ts = tracker.update(np.array(new_results.boxes.data.tolist()), im) # --> (x, y, x, y, id, conf, cls)\n    except:\n        ts = new_results\n        \n    xyxys = ts[:,0:4].astype('int') # float64 to int\n    ids = ts[:, 4].astype('int') # float64 to int\n    confs = np.round(ts[:, 5], 2)\n    clss = ts[:, 6]\n\n    # print bboxes with their associated id, cls and conf\n    if ts.shape[0] != 0:\n        for xyxy, id, conf, cls in zip(xyxys, ids, confs, clss):\n            im = cv2.rectangle(\n                im,\n                (xyxy[0], xyxy[1]),\n                (xyxy[2], xyxy[3]),\n                color,\n                thickness\n            )\n            cv2.putText(\n                im,\n                f'id: {id}, conf: {conf}, c: {cls}',\n                (xyxy[0], xyxy[1]-10),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                fontscale,\n                color,\n                thickness\n            )\n\n    # show the frame to our screen\n\n    writer.write(im)\n\n\nvid.release()\nwriter.release()\nprint(\"Task Completed\")","metadata":{"execution":{"iopub.status.busy":"2024-05-20T04:58:43.184687Z","iopub.execute_input":"2024-05-20T04:58:43.185714Z","iopub.status.idle":"2024-05-20T05:03:04.299450Z","shell.execute_reply.started":"2024-05-20T04:58:43.185656Z","shell.execute_reply":"2024-05-20T05:03:04.297894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current, peak = tracemalloc.get_traced_memory()\ntracemalloc.stop()\n\n# Calculate the time taken\nend_time = time.time()\nexecution_time = end_time - start_time\n\nExecution_time = np.round(execution_time,2)\nCurrent_memory = np.round(current / 1024 / 1024, 2)\nPeak_memory = np.round(peak / 1024 / 1024, 2)\n\nperformance_DeepOCSORT = [Execution_time, Current_memory, Peak_memory]\n\nprint(f\"Execution time: {Execution_time} seconds\")\nprint(f\"Current memory usage: {Current_memory} MB\")\nprint(f\"Peak memory usage: {Peak_memory} MB\")","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:03:04.301940Z","iopub.execute_input":"2024-05-20T05:03:04.302416Z","iopub.status.idle":"2024-05-20T05:03:04.323884Z","shell.execute_reply.started":"2024-05-20T05:03:04.302367Z","shell.execute_reply":"2024-05-20T05:03:04.322853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing StrongSORT\n","metadata":{}},{"cell_type":"code","source":"#help(StrongSORT)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:03:04.324926Z","iopub.execute_input":"2024-05-20T05:03:04.325167Z","iopub.status.idle":"2024-05-20T05:03:04.337594Z","shell.execute_reply.started":"2024-05-20T05:03:04.325146Z","shell.execute_reply":"2024-05-20T05:03:04.336795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\ntracemalloc.start()","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:03:04.338717Z","iopub.execute_input":"2024-05-20T05:03:04.339009Z","iopub.status.idle":"2024-05-20T05:03:04.348986Z","shell.execute_reply.started":"2024-05-20T05:03:04.338985Z","shell.execute_reply":"2024-05-20T05:03:04.347596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tracker = StrongSORT(\n    model_weights=Path('mobilenetv2_x1_4_dukemtmcreid.pt'), # which ReID model to use\n    device=device,\n    fp16=fp16,\n)\ntracker.n_init = 1\nvid = cv2.VideoCapture(source)\nwriter = create_video_writer(vid, out_dir +\"StrongSort.mp4\")\nwhile True:\n    clear_output(wait=False)\n    ret, im = vid.read()\n\n    # if video frames end\n    if not ret:\n        break\n    else:\n        #im_resized = cv2.resize(im, (640, 640))\n        results = model.predict(im)[0]\n\n    if np.array(results.boxes.data.tolist()).ndim < 2:\n        continue\n\n    new_results = findTargetObjectIndex(im, results, target_obj_img, frameNo, obj_dir='')\n    try:\n        ts = tracker.update(np.array(new_results.boxes.data.tolist()), im) # --> (x, y, x, y, id, conf, cls)\n        if (ts.size == 0):\n            ts = np.array( [[0,0,0,0,0,0,0]] )\n    except:\n        ts = np.array( [[0,0,0,0,0,0,0]] )\n\n    xyxys = ts[:,0:4].astype('int') # float64 to int\n    ids = ts[:, 4].astype('int') # float64 to int\n    confs = np.round(ts[:, 5])\n    clss = ts[:, 6]\n\n    # print bboxes with their associated id, cls and conf\n    if ts.shape[0] != 0:\n        for xyxy, id, conf, cls in zip(xyxys, ids, confs, clss):\n            im = cv2.rectangle(\n                im,\n                (xyxy[0], xyxy[1]),\n                (xyxy[2], xyxy[3]),\n                color,\n                thickness\n            )\n            cv2.putText(\n                im,\n                f'id: {id}, conf: {conf}, c: {cls}',\n                (xyxy[0], xyxy[1]-10),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                fontscale,\n                color,\n                thickness\n            )\n\n    # show the frame to our screen\n    \n    writer.write(im)\n\n\nvid.release()\nwriter.release()\nprint(\"Task Completed\")","metadata":{"_uuid":"7da1b674-3a9e-4834-9e7d-a7b5782cf2f2","_cell_guid":"bcc3df86-465d-436d-851a-827e603d68a9","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-20T05:37:32.405480Z","iopub.execute_input":"2024-05-20T05:37:32.405871Z","iopub.status.idle":"2024-05-20T05:41:53.473469Z","shell.execute_reply.started":"2024-05-20T05:37:32.405840Z","shell.execute_reply":"2024-05-20T05:41:53.471681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current, peak = tracemalloc.get_traced_memory()\ntracemalloc.stop()\n\n# Calculate the time taken\nend_time = time.time()\nexecution_time = end_time - start_time\n\nExecution_time = np.round(execution_time,2)\nCurrent_memory = np.round(current / 1024 / 1024, 2)\nPeak_memory = np.round(peak / 1024 / 1024, 2)\nperformance_StrongSORT = [Execution_time, Current_memory, Peak_memory]\n\nprint(f\"Execution time: {Execution_time} seconds\")\nprint(f\"Current memory usage: {Current_memory} MB\")\nprint(f\"Peak memory usage: {Peak_memory} MB\")","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:07:28.007057Z","iopub.execute_input":"2024-05-20T05:07:28.007574Z","iopub.status.idle":"2024-05-20T05:07:28.026712Z","shell.execute_reply.started":"2024-05-20T05:07:28.007496Z","shell.execute_reply":"2024-05-20T05:07:28.025660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing BoTSORT","metadata":{}},{"cell_type":"code","source":"#help(BoTSORT)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:07:28.028116Z","iopub.execute_input":"2024-05-20T05:07:28.028773Z","iopub.status.idle":"2024-05-20T05:07:28.040836Z","shell.execute_reply.started":"2024-05-20T05:07:28.028740Z","shell.execute_reply":"2024-05-20T05:07:28.039979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\ntracemalloc.start()","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:07:28.041848Z","iopub.execute_input":"2024-05-20T05:07:28.042126Z","iopub.status.idle":"2024-05-20T05:07:28.052046Z","shell.execute_reply.started":"2024-05-20T05:07:28.042103Z","shell.execute_reply":"2024-05-20T05:07:28.050422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from boxmot import BoTSORT\ntracker = BoTSORT(\n    model_weights=Path('osnet_x0_25_msmt17.pt'),\n    device=device,\n    fp16=fp16,\n)\nvid = cv2.VideoCapture(source)\nwriter = create_video_writer(vid, out_dir + \"BoTSORT.mp4\")\n\nwhile True:\n    clear_output(wait=False)\n    ret, im = vid.read()\n\n    # if video frames end\n    if not ret:\n        break\n    else:\n        #im_resized = cv2.resize(im, (640, 640))\n        results = model.predict(im)[0]\n\n    if np.array(results.boxes.data.tolist()).ndim < 2:\n        continue\n\n    new_results = findTargetObjectIndex(im, results, target_obj_img, frameNo, obj_dir='')\n    try:\n        ts = tracker.update(np.array(new_results.boxes.data.tolist()), im) # --> (x, y, x, y, id, conf, cls)\n        if (ts.size == 0):\n            ts = np.array( [[0,0,0,0,0,0,0]] )\n    except:\n        ts = np.array( [[0,0,0,0,0,0,0]] )\n        \n\n    xyxys = ts[:,0:4].astype('int') # float64 to int\n    ids = ts[:, 4].astype('int') # float64 to int \n    confs = np.round(ts[:, 5])\n    clss = ts[:, 6]\n\n    # print bboxes with their associated id, cls and conf\n    if ts.shape[0] != 0:\n        for xyxy, id, conf, cls in zip(xyxys, ids, confs, clss):\n            im = cv2.rectangle(\n                im,\n                (xyxy[0], xyxy[1]),\n                (xyxy[2], xyxy[3]),\n                color,\n                thickness\n            )\n            cv2.putText(\n                im,\n                f'id: {id}, conf: {conf}, c: {cls}',\n                (xyxy[0], xyxy[1]-10),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                fontscale,\n                color,\n                thickness\n            )\n\n    # show the frame to our screen\n    \n    writer.write(im)\n\n\nvid.release()\nwriter.release()\nprint(\"Task Completed\")","metadata":{"_uuid":"d9593daa-bbb5-42b4-8dd8-cedf003536c2","_cell_guid":"6b06d5c4-ee5b-4a67-bcf8-1952810da9e5","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-20T05:07:28.054434Z","iopub.execute_input":"2024-05-20T05:07:28.055577Z","iopub.status.idle":"2024-05-20T05:12:06.393371Z","shell.execute_reply.started":"2024-05-20T05:07:28.055492Z","shell.execute_reply":"2024-05-20T05:12:06.391945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current, peak = tracemalloc.get_traced_memory()\ntracemalloc.stop()\n\n# Calculate the time taken\nend_time = time.time()\nexecution_time = end_time - start_time\n\nExecution_time = np.round(execution_time,2)\nCurrent_memory = np.round(current / 1024 / 1024, 2)\nPeak_memory = np.round(peak / 1024 / 1024, 2)\n\nperformance_BoTSORT = [Execution_time, Current_memory, Peak_memory]\n\nprint(f\"Execution time: {Execution_time} seconds\")\nprint(f\"Current memory usage: {Current_memory} MB\")\nprint(f\"Peak memory usage: {Peak_memory} MB\")","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:12:06.396333Z","iopub.execute_input":"2024-05-20T05:12:06.397246Z","iopub.status.idle":"2024-05-20T05:12:06.419538Z","shell.execute_reply.started":"2024-05-20T05:12:06.397194Z","shell.execute_reply":"2024-05-20T05:12:06.418487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing BYTETracker","metadata":{}},{"cell_type":"code","source":"#help(BYTETracker)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:12:06.420850Z","iopub.execute_input":"2024-05-20T05:12:06.421208Z","iopub.status.idle":"2024-05-20T05:12:06.434153Z","shell.execute_reply.started":"2024-05-20T05:12:06.421172Z","shell.execute_reply":"2024-05-20T05:12:06.433331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\ntracemalloc.start()","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:12:06.435461Z","iopub.execute_input":"2024-05-20T05:12:06.435807Z","iopub.status.idle":"2024-05-20T05:12:06.445577Z","shell.execute_reply.started":"2024-05-20T05:12:06.435783Z","shell.execute_reply":"2024-05-20T05:12:06.444010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from boxmot import BYTETracker\ntracker =  BYTETracker()\nvid = cv2.VideoCapture(source)\nwriter = create_video_writer(vid, out_dir+\"BYTETracker.mp4\")\n\nwhile True:\n    clear_output(wait=False)\n    ret, im = vid.read()\n\n    # if video frames end\n    if not ret:\n        break\n    else:\n        #im_resized = cv2.resize(im, (640, 640))\n        results = model.predict(im)[0]\n\n    if np.array(results.boxes.data.tolist()).ndim < 2:\n        continue\n\n    new_results = findTargetObjectIndex(im, results, target_obj_img, frameNo, obj_dir='')\n    try:\n        ts = tracker.update(np.array(new_results.boxes.data.tolist()), im) # --> (x, y, x, y, id, conf, cls)\n        if (ts.size == 0):\n            ts = np.array( [[0,0,0,0,0,0,0]] )\n    except:\n        ts = np.array( [[0,0,0,0,0,0,0]] )\n        \n        \n    xyxys = ts[:,0:4].astype('int') # float64 to int\n    ids = ts[:, 4].astype('int') # float64 to int\n    confs = np.round(ts[:, 5])\n    clss = ts[:, 6]\n\n    # print bboxes with their associated id, cls and conf\n    if ts.shape[0] != 0:\n        for xyxy, id, conf, cls in zip(xyxys, ids, confs, clss):\n            im = cv2.rectangle(\n                im,\n                (xyxy[0], xyxy[1]),\n                (xyxy[2], xyxy[3]),\n                color,\n                thickness\n            )\n            cv2.putText(\n                im,\n                f'id: {id}, conf: {conf}, c: {cls}',\n                (xyxy[0], xyxy[1]-10),\n                cv2.FONT_HERSHEY_SIMPLEX,\n                fontscale,\n                color,\n                thickness\n            )\n\n    # show the frame to our screen\n    \n    writer.write(im)\n\n\nvid.release()\nwriter.release()\nprint(\"Task Completed\")","metadata":{"_uuid":"01eb20ab-a0fe-4065-9ef5-3fc610f9ddf9","_cell_guid":"4eef3134-fe31-4173-b389-cceb0e6281dd","collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-05-20T05:12:06.447451Z","iopub.execute_input":"2024-05-20T05:12:06.447963Z","iopub.status.idle":"2024-05-20T05:16:00.285751Z","shell.execute_reply.started":"2024-05-20T05:12:06.447914Z","shell.execute_reply":"2024-05-20T05:16:00.283753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"current, peak = tracemalloc.get_traced_memory()\ntracemalloc.stop()\n\n# Calculate the time taken\nend_time = time.time()\nexecution_time = end_time - start_time\n\nExecution_time = np.round(execution_time,2)\nCurrent_memory = np.round(current / 1024 / 1024, 2)\nPeak_memory = np.round(peak / 1024 / 1024, 2)\n\nperformance_BYTETracker = [Execution_time, Current_memory, Peak_memory]\n\nprint(f\"Execution time: {Execution_time} seconds\")\nprint(f\"Current memory usage: {Current_memory} MB\")\nprint(f\"Peak memory usage: {Peak_memory} MB\")","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:16:00.288486Z","iopub.execute_input":"2024-05-20T05:16:00.289027Z","iopub.status.idle":"2024-05-20T05:16:00.306772Z","shell.execute_reply.started":"2024-05-20T05:16:00.288975Z","shell.execute_reply":"2024-05-20T05:16:00.305721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:16:00.308276Z","iopub.execute_input":"2024-05-20T05:16:00.308690Z","iopub.status.idle":"2024-05-20T05:16:00.322387Z","shell.execute_reply.started":"2024-05-20T05:16:00.308650Z","shell.execute_reply":"2024-05-20T05:16:00.321405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(list(zip(performance_DeepOCSORT, performance_StrongSORT, performance_BoTSORT, performance_BYTETracker)),\n                  columns = ['DeepOCSORT', 'StrongSORT', 'BoTSORT', 'BYTETracker'],\n                  index = ['Execution_time(s)', 'Current_memory(MB)', 'Peak_memory(MB)'])\n\ndf.to_csv(out_dir + 'SimulationPerformance.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:16:00.323730Z","iopub.execute_input":"2024-05-20T05:16:00.324148Z","iopub.status.idle":"2024-05-20T05:16:00.339661Z","shell.execute_reply.started":"2024-05-20T05:16:00.324113Z","shell.execute_reply":"2024-05-20T05:16:00.338500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\nfor i in [4,5,6]:\n    OUTPUT_NAME = f'/kaggle/working/TrackResultsTest{i}'\n    DIRECTORY_TO_ZIP = f'/kaggle/working/Test{i}'\n    \n    print(DIRECTORY_TO_ZIP)\n    shutil.make_archive(OUTPUT_NAME, 'zip', DIRECTORY_TO_ZIP)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T05:58:52.688826Z","iopub.execute_input":"2024-05-20T05:58:52.689229Z","iopub.status.idle":"2024-05-20T06:01:32.247353Z","shell.execute_reply.started":"2024-05-20T05:58:52.689167Z","shell.execute_reply":"2024-05-20T06:01:32.245778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
